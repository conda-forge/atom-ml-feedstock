{% set name = "atom-ml" %}
{% set version = "5.0.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: a8a578f6ed672d5a3bb02200dc173ecb97353ea9cd31e1a76e14740237c6415f


build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . --no-deps -vv

requirements:
  host:
    - python >=3.8
    - pip
    - pdm
  run:
    - python >=3.8
    - category_encoders
    - explainerdashboard
    - dill
    - evalml
    - gplearn
    - imbalanced-learn
    - featuretools
    - joblib
    - matplotlib-base
    - mlflow
    - nltk
    - numpy
    - optuna
    - pandas
    - pandas-profiling
    - plotly
    - shap
    - schemdraw
    - scikit-learn
    - scipy
    - typeguard
    - wordcloud
    - zoofs

test:
  requires:
    - pytest
    - pytest-cov
    - py-xgboost  # [not win]
    - lightgbm
    - catboost
  source_files:
    - tests
  commands:
    - pip install -U gradio  # Not available in conda-forge
    - pip install -U scikit-learn-intelex  # Conda implementation fails, see https://github.com/intel/scikit-learn-intelex/issues/1049
    - pip install -U evalml  # Conda version is outdated, see https://github.com/alteryx/evalml/issues/3866
    - pytest

about:
  home: http://github.com/tvdboom/ATOM
  license: MIT
  license_file: LICENSE
  summary: A Python package for fast exploration of machine learning pipelines
  description: |
    During the exploration phase of a machine learning project, a data
    scientist tries to find the optimal pipeline for his specific use case.
    This usually involves applying standard data cleaning steps, creating
    or selecting useful features, trying out different models, etc. Testing
    multiple pipelines requires many lines of code, and writing it all in
    the same notebook often makes it long and cluttered. On the other hand,
    using multiple notebooks makes it harder to compare the results and to
    keep an overview. On top of that, refactoring the code for every test
    can be time-consuming. How many times have you conducted the same action
    to pre-process a raw dataset? How many times have you copy-and-pasted
    code from an old repository to re-use it in a new use case?
    ATOM is here to help solve these common issues. The package acts as
    a wrapper of the whole machine learning pipeline, helping the data
    scientist to rapidly find a good model for his problem. Avoid
    endless imports and documentation lookups. Avoid rewriting the same
    code over and over again. With just a few lines of code, it's now
    possible to perform basic data cleaning steps, select relevant
    features and compare the performance of multiple models on a given
    dataset, providing quick insights on which pipeline performs best
    for the task at hand.
  doc_url: https://tvdboom.github.io/ATOM/
  dev_url: http://github.com/tvdboom/ATOM/tree/development

extra:
  recipe-maintainers:
    - tvdboom
