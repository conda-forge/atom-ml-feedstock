{% set name = "atom-ml" %}
{% set version = "5.1.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 24b2b4edd304ff0b1200e13f57210c5a57835f05ee49b171cd980eb7a11462d1


build:
  number: 1
  noarch: python
  script: {{ PYTHON }} -m pip install . --no-deps -vv

requirements:
  host:
    - python >=3.8
    - pip
    - pdm
    - pdm-pep517
  run:
    - catboost
    - category_encoders
    - dill
    - gplearn
    - imbalanced-learn
    - featuretools
    - joblib
    - lightgbm
    - matplotlib-base
    - mlflow
    - modin-ray
    - nltk
    - numpy
    - optuna
    - pandas
    - plotly
    - py-xgboost  # [not win]
    - ray-serve
    - schemdraw
    - scikit-learn
    - scikit-learn-intelex; platform_machine == 'x86_64' or platform_machine == 'AMD64'
    - scipy
    - shap
    - wordcloud
    - zoofs
    - pip:
      - dagshub  # Not available in conda
      - evalml  # Conda version is outdated, see https://github.com/alteryx/evalml/issues/3866
      - explainerdashboard  # Fails for some reason with conda
      - gradio  # Not available in conda
      - ydata-profiling  # Not available in conda

test:
  requires:
    - pytest
    - scikeras
    - tensorflow
  source_files:
    - tests
  commands:
    - export GIT_PYTHON_REFRESH=quiet  # Needed to make dagshub import work
    - pytest

about:
  home: http://github.com/tvdboom/ATOM
  license: MIT
  license_file: LICENSE
  summary: A Python package for fast exploration of machine learning pipelines
  description: |
    During the exploration phase of a machine learning project, a data
    scientist tries to find the optimal pipeline for his specific use case.
    This usually involves applying standard data cleaning steps, creating
    or selecting useful features, trying out different models, etc. Testing
    multiple pipelines requires many lines of code, and writing it all in
    the same notebook often makes it long and cluttered. On the other hand,
    using multiple notebooks makes it harder to compare the results and to
    keep an overview. On top of that, refactoring the code for every test
    can be time-consuming. How many times have you conducted the same action
    to pre-process a raw dataset? How many times have you copy-and-pasted
    code from an old repository to re-use it in a new use case?
    ATOM is here to help solve these common issues. The package acts as
    a wrapper of the whole machine learning pipeline, helping the data
    scientist to rapidly find a good model for his problem. Avoid
    endless imports and documentation lookups. Avoid rewriting the same
    code over and over again. With just a few lines of code, it's now
    possible to perform basic data cleaning steps, select relevant
    features and compare the performance of multiple models on a given
    dataset, providing quick insights on which pipeline performs best
    for the task at hand.
  doc_url: https://tvdboom.github.io/ATOM/
  dev_url: http://github.com/tvdboom/ATOM/tree/development

extra:
  recipe-maintainers:
    - tvdboom
