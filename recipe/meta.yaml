{% set name = "atom-ml" %}
{% set version = "5.1.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: f97fa6e5e4f56983373124b8214d4a71cd61fe0c4e24566825567e2be4edf16c


build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . --no-deps -vv

requirements:
  host:
    - python >=3.8
    - pip
    - pdm
    - pdm-pep517
  run:
    - python >=3.8
    - category_encoders
    - dill
    - gplearn
    - imbalanced-learn
    - featuretools
    - joblib
    - matplotlib-base
    - mlflow
    - modin-ray
    - nltk
    - numpy
    - optuna
    - pandas
    - plotly
    - ray-serve
    - shap
    - scikit-learn
    - scikit-learn-intelex
    - scipy
    - zoofs

test:
  requires:
    - pytest
    - catboost
    - evalml
    - explainerdashboard
    - gradio
    - lightgbm
    - schemdraw
    - wordcloud
    - py-xgboost  # [not win]
  source_files:
    - tests
  commands:
    - pip install -U dagshub ydata-profiling  # Not available in conda-forge
    - pip install -U evalml  # Conda version is outdated, see https://github.com/alteryx/evalml/issues/3866
    - export GIT_PYTHON_REFRESH=quiet  # Needed to make dagshub import work
    - pytest

about:
  home: http://github.com/tvdboom/ATOM
  license: MIT
  license_file: LICENSE
  summary: A Python package for fast exploration of machine learning pipelines
  description: |
    During the exploration phase of a machine learning project, a data
    scientist tries to find the optimal pipeline for his specific use case.
    This usually involves applying standard data cleaning steps, creating
    or selecting useful features, trying out different models, etc. Testing
    multiple pipelines requires many lines of code, and writing it all in
    the same notebook often makes it long and cluttered. On the other hand,
    using multiple notebooks makes it harder to compare the results and to
    keep an overview. On top of that, refactoring the code for every test
    can be time-consuming. How many times have you conducted the same action
    to pre-process a raw dataset? How many times have you copy-and-pasted
    code from an old repository to re-use it in a new use case?
    ATOM is here to help solve these common issues. The package acts as
    a wrapper of the whole machine learning pipeline, helping the data
    scientist to rapidly find a good model for his problem. Avoid
    endless imports and documentation lookups. Avoid rewriting the same
    code over and over again. With just a few lines of code, it's now
    possible to perform basic data cleaning steps, select relevant
    features and compare the performance of multiple models on a given
    dataset, providing quick insights on which pipeline performs best
    for the task at hand.
  doc_url: https://tvdboom.github.io/ATOM/
  dev_url: http://github.com/tvdboom/ATOM/tree/development

extra:
  recipe-maintainers:
    - tvdboom
